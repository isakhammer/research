\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Project 1 Notes}
\author{isakhammer }
\date{2020}

%%%% DEPENDENCIES v1.2 %%%%%%

\usepackage{natbib}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{mathtools}
%\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{todonotes}
\usepackage{float}


\usepackage{hyperref} 
\hypersetup{
  colorlinks=true, %set true if you want colored links
  linktoc=all,     %set to all if you want both sections and subsections linked
  linkcolor=blue,  %choose some color if you want links to stand out
} 
\hypersetup{linktocpage}


% inscape-figures
\usepackage{import}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{xcolor}
\newcommand{\incfig}[2][1]{%
\def\svgwidth{#1\columnwidth}
\import{./figures/}{#2.pdf_tex} } \pdfsuppresswarningpagegroup=1

% Box environment
\usepackage{tcolorbox}
\usepackage{mdframed}
\newmdtheoremenv{definition}{Definition}[section]
\newmdtheoremenv{theorem}{Theorem}[section]
\newmdtheoremenv{lemma}{Lemma}[section]

% \DeclareMathOperator{\span}{span}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}
%\newtheorem{example}{Example}

\newcommand{\newpara}
  {
  \vskip 0.4cm
  }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{document}
\maketitle
\tableofcontents
\newpage

\newpage
\section{Problem 1}%
\label{sec:problem_1}

Let normal matrices, those with diagonalization be on the form \[
A = U \Lambda U^{H} 
\] 
Where $\Lambda $ is a diagonal complex $n\times n $ matrix and $U$ a unitary (complex) matrix such that $U ^{H} U = I$ (recall that $U^{H}$ is the complex conjugate of $U^{T}$ ).
\newpara
Show that for any such matrix, one has $\|A\|_{2} = \rho \left( A \right)$, where $\rho \left( A \right) $ is the spectral radius of $A$ .

\subsection{Proof}%
\label{sub:proof}

  \textbf{Answer.} 
\begin{proof}
  Starting with the definition of a subordinate matrix norm \cite{sul} can we let \[
  \|A\|_{2}^{2} = \sup_{x \neq 0} \frac{\left<Ax, Ax \right>}{ \left<x,x \right>} .
  \] 
  \textbf{Note sure if this is the correct notation for 2-norm.} 
   Indeed, by using the assumption that $U^{H} U = I$ and substituting $Uy =  x$ can we show that \[
    \|A\|_{}^{2} = \sup_{x \neq 0} \frac{\left<Ax, Ax \right>}{\left<x,x \right>}  = \sup_{y\neq 0}  \frac{\left<AU y, A U y \right>}{ \left<U y, Uy \right>} = \sup_{y \neq 0} \frac{\left<U^{H} A^{H} A U y,y \right>}{\left<y,y \right>} 
  \] 
    % \textbf{Kinda sketchy argument, given in Quartentoni page 41/664. In fact, I do not believe it is true to assume A is hermetian/unitary.}  
  \newpara
  Recall the property $A = U \Lambda  U^{H}$ and thus
  \[
    \begin{split}
  A^{H} A   & = U \Lambda ^{H} U^{H} U \Lambda U^{H}  \\
   & = U \Lambda ^{H} \Lambda U^{H}.   \\
    \end{split} 
  \] 
  As a consequence do we end up with \[
    \begin{split}
  \sup_{y \neq 0} \frac{\left<U^{H} A^{H} A U y, y  \right>}{\left<y,y \right>}   & = \sup_{y\neq 0}  \frac{\left<U^{H} U \Lambda ^{H} \Lambda  U^{H} U  y, y\right>}{ \left<y,y \right>}  \\
  &=  \sup_{y \neq 0} \frac{\left<\Lambda ^{H} \Lambda  y, y \right>}{\left<y,y \right>}  \\  
  &=   \sup_{ y \neq 0}  \frac{\sum_{i=1}^{n}  \left\lvert \lambda _{i} \right\rvert ^2  \left| y_{i} \right|^2}{ \sum_{i=1}^{n}  \left| y_{i} \right|^2}  = \max _{i} \left( \left\lvert \lambda_{i}  \right\rvert ^{2}  \right)  \\
    \end{split} .
  \] 
  Given the definition of a spectral radius \cite{quart} characterized by \[
  \rho \left( A \right) = \max_{i} \left\lvert \lambda_{i}  \right\rvert    .
  \] 
  Which completes the proof of $ \|A\|_{2} = \rho \left( A \right)$.
   
\end{proof}

\subsection{Note}%
\label{sub:note}

Let say $A = U\Lambda U^{H}$. Then is it not possible to get any useful answers. 
    \begin{enumerate}[label=(\roman*)]
      \item Lets compute $AA$ \[
      A A = U \Lambda U^{H} U \Lambda  U^{H} = U \Lambda  \Lambda  U ^{H}
      \] 
    \item Lets compute $A^{H} A$ 
      \[
      A^{H} A = U \Lambda ^{H} U^{H} U \Lambda U^{H} = U \Lambda ^{H} \Lambda U^{H}
      \] 
    \item Lets compute  $A A^{H}$ \[
    A A^{H} = U \Lambda U^{H}  U \Lambda ^{H} U^{H}  = U \Lambda  \Lambda ^{H} U^{H}.
    \] 
    \end{enumerate}

\newpage

\section{Problem 2}%
\label{sec:problem_2}

Consider the $n \times n $ matrix $A$ whise nonzero elements are located on its unit subdiagonal , i.e. $A_{i+1, i} = 1$ for $i = 1, \ldots, n-1$\[
A = \begin{bmatrix} 
  0  &  \ldots  &  \ldots  & 0 \\
  1  &  0  &    & \vdots  \\
  \vdots   & \ddots   & \ddots   &  \vdots   \\
  0  &  \ldots     & 1  & 0 
\end{bmatrix} 
\] 

\begin{enumerate}[label=(\alph*)]
  \item  What are the eigenvalues of $A$ ? What would the Gershgorin theorem tell us abou the location of the eigenvalues of $A$.
  \item  Now construct the matrix $\hat{A}$ by adding a small number $\epsilon $ in the $\left( 1, n \right)$- element of $A$ (so that $\hat{A} = A  +  \epsilon e_{1} e_{n}^{T} $. Show that \[
      \rho \left( \hat{A} \right) = \epsilon ^{\frac{1}{n} }
  \] 
  And fins an expression for the eigenvalues and eigenvectors of $\hat{A}$. 
\item Derive an exact expression for the condition number $K_{2} \left( \hat{A} \right) =  \|\hat{A}\|_{2}^{} = \|\hat{A}^{-1}\|_{2}^{}$.

  \end{enumerate}

  \subsection{Answer a}%
  \label{sub:answer_a}
  
      \textbf{Answer.} 

\newpara
The eigenvalues can be computed such that \[
  \begin{split}
  det \left( A - \lambda   \right) &= \begin{vmatrix} 
  -\lambda &   &   &      \ldots  & 0 & 0 \\
  1  &  -\lambda  & \ldots  &   &   & 0 \\
  0  & 1  & - \lambda   &  \ldots  &   & 0 \\
  \vdots  &   &  &   \ddots  \\
  0  &  \ldots  &  &    & 1    & - \lambda      \\
  \end{vmatrix} 
    \\
   &= -\lambda  \begin{vmatrix} 
   -\lambda   &  \ldots  &      & 0 \\
  1  & - \lambda  &      \\
  \vdots  & &    \ddots  \\
  0  &  \ldots & 1    & -\lambda      \\
  \end{vmatrix} 
    \\
   &=\left( -1 \right)^{n}   \lambda^{n}  = 0 \quad   \implies  \quad \quad \lambda  = 0
  \end{split} 
\] 
Which concludes that we did only find a trivial solution.

    \subsection{Answer b}%
\label{sub:answer_b_}


    \textbf{Answer.} 
    We can observe that \[
    \hat{A} = A + \varepsilon e_{1}e_{n}^{T} = \begin{pmatrix}
    0    &   &  \ldots           &    &  \varepsilon  \\
    1  & 0  &  \ldots \\
    0  &  1  & \ddots  \\
    \vdots   &   &  \ddots   &  \ddots   & \\
     0  &  \ldots  &   &  1  & 0
    \end{pmatrix} 
    \] 
    We can then find the eigenvalues by computing\[
      \begin{split}
    det \left(  \hat{A} - \lambda \right)  & = \begin{vmatrix}
    -\lambda     &   &  \ldots           &    &  \varepsilon  \\
    1  & -\lambda   &  \ldots \\
    0  &  1  & \ddots  \\
    \vdots   &   &  \ddots   &  \ddots   & \\
     0  &  \ldots  &   &  1  & -\lambda 
    \end{vmatrix}  \\
    &=  \left( -1 \right)^{n} \lambda ^{n}  + \left( -1 \right)^{n+1}\varepsilon 
     \begin{vmatrix}
    1  & -\lambda   &  \ldots \\
    0  &  1  & \ddots  \\
    \vdots   &   &  \ddots   &  \ddots   & \\
     0  &  \ldots  &   &  1  & -\lambda 
    \end{vmatrix}  \\
     \\
     &=  \left( -1 \right)^{n} \lambda ^{n} + \left( -1 \right)^{n+1}\varepsilon  = 0 \quad        \\
      \end{split} 
    \] 
    Solvin this equation do we obtain \[
     \implies  \lambda     & = \varepsilon^{\frac{1}{n}} = \begin{cases}
       , \quad   &  n = 0 \\
       , \quad   &  n= 1 \\
     \end{cases}
    \] 
    As we can see can $\lambda $ have several complex solutions depending on the value $n$. However, we can conclude that $\left\lvert \lambda  \right\rvert = \varepsilon ^{\frac{1}{n}}$ thus
     \[
    \rho \left( \hat{A} \right) = \varepsilon ^{\frac{1}{n}}.
    \] 
    Which completes the task.


\newpage
\section{References}%
\label{sec:references}

\bibliographystyle{plain}
\bibliography{references}


\end{document}

